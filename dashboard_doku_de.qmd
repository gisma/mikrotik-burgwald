---
title: "README dashboard"
subtitle: "version 0.1"
author: "Chris Reudenbach"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true      
    number-depth: 3           

    code-copy: true
    code-link: true
    code-overflow: wrap
    code-fold: true
    highlight-style: github
execute:
  mermaid: true
diagram:
  mermaid:
    engine: kroki
    kroki-url: https://kroki.io
---

# TTN Dashboard ‚Äì Nutzung, Konfiguration und Deployment

Dieses Repository enth√§lt ein Python-Skript, das aus **The Things Network (TTN) Storage** ein HTML-Dashboard erzeugt.  
Es erkennt automatisch alle Devices, zieht deren Uplinks, schreibt pro Ger√§t Parquet-Dateien und erstellt interaktive Plots.

---

## Schnellstart (lokal)

1. (Optional) Erstelle `scripts/.env`:

```env
   TTN_APP_ID=gisma-hydro-testbed
   TTN_REGION=eu1
   TTN_API_KEY=NNSXS_...
   RUN_DASH=1
   TTN_AFTER_DAYS=2
   DELAY_BETWEEN_DEVICES=0.3
   # Health-Report (optional):
   # STALE_HOURS=3
   # DEV_INCLUDE=dds75-lb-.*
   # DEV_EXCLUDE=
```

2. Ausf√ºhren:

   ```bash
   python scripts/pull_all_devices.py
   ```

3. Ergebnisse liegen unter:

   * `assets/data.html` (Haupt-Dashboard)
   * `assets/debug.html` (Rohdaten-Beispiele & Parquet-Previews)
   * Health-Report: `assets/devices_used.txt` und `assets/devices_used.csv`

---

## Environment-Variablen

Diese k√∂nnen in `.env`, in der Shell oder im GitHub Actions Workflow (`env:`) gesetzt werden.
Fehlt etwas, werden Standardwerte genutzt.

### Pflicht

* `TTN_APP_ID` ‚Äî deine TTN Application ID (z. B. `gisma-hydro-testbed`)
* `TTN_REGION` ‚Äî TTN-Cluster (z. B. `eu1`)
* `TTN_API_KEY` ‚Äî NNSXS-Key mit folgenden Scopes:

  * **View end devices** (f√ºr Auto-Discovery)
  * **View application packages and associations** (Storage)
  * (hilfreich) **View application info**, **Read application traffic/data**

### Optional (Verhalten)

* `RUN_DASH` (`"1"`)
  `1` = HTML-Dashboard erzeugen; `0` = CLI-Testmodus (siehe unten).
* `TTN_AFTER_DAYS` (`"2"`)
  Gleitendes Fenster: *jetzt ‚àí N Tage*.
  Falls bereits Parquet-Daten existieren, setzt das Skript am letzten Timestamp fort.
* `DELAY_BETWEEN_DEVICES` (`"0.3"`)
  Sekunden Pause zwischen den Devices (gegen Rate-Limits).
* `DEVICES` (leer)
  Liste mit Device-IDs (whitespace-separiert). Wenn **leer**, werden **alle Devices automatisch** erkannt.

### Health-Report

* `STALE_HOURS` (`"3"`) ‚Äî Ger√§t gilt als `STALE (xh)`, wenn `last_seen` √§lter ist.
* `DEV_INCLUDE` (`".*"`) ‚Äî Regex-Filter f√ºr Devices, die eingeschlossen werden sollen.
* `DEV_EXCLUDE` (leer) ‚Äî Regex-Filter f√ºr Devices, die ausgeschlossen werden sollen.

---

## Outputs & Struktur

* `data/` ‚Äî Parquet-Dateien pro Ger√§t: `data/<device>.parquet`
* `assets/`

  * `data.html` ‚Äî Dashboard
  * `debug.html` ‚Äî Debug-Ansicht mit Rohdaten
  * `devices_used.txt` ‚Äî **lesbarer** Health-Report
  * `devices_used.csv` ‚Äî **maschinenlesbarer** Health-Report

> Hinweis: Beim Start kann `devices_used.txt` kurzzeitig nur die Liste der Devices enthalten. Am Ende wird sie mit dem Health-Report √ºberschrieben.

---

## CLI Smoke-Test

Einzelnes Device abrufen (ohne Dashboard):

```bash
RUN_DASH=0 python scripts/pull_all_devices.py --device dds75-lb-13 --hours 6 -v
```

* `--hours` √ºberschreibt `TTN_AFTER_DAYS` nur f√ºr diesen Lauf.
* Daten werden in `data/<device>.parquet` gespeichert und dedupliziert.

---

## GitHub Actions (Pages oder Artefakt)

Beispiel-Workflow:

```yaml
name: TTN all devices ‚Üí Pages

on:
  schedule:
    - cron: "*/30 * * * *"     # alle 30 Minuten (UTC)
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: ttn-pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest

    env:
      TTN_APP_ID:  ${{ secrets.TTN_APP_ID }}
      TTN_REGION:  ${{ secrets.TTN_REGION }}
      TTN_API_KEY: ${{ secrets.TTN_API_KEY }}
      THEME_DEFAULT: "light"                 # optionales Theme f√ºrs Dashboard
      DEBUG_RECENT_MINUTES: "90"             # steuert die Debug-Tabelle (zuletzt X Minuten)

    steps:
      - name: Checkout (full history)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Sync branch (rebase)
        env:
          BRANCH: ${{ github.ref_name }}
        run: |
          git config user.name  "ttn-bot"
          git config user.email "ttn-bot@example.com"
          git checkout "$BRANCH"
          git pull --rebase origin "$BRANCH" || true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas plotly pyarrow python-dotenv

      # Erzwingt HTML-Build und gen√ºgend Storage-Fenster
      - name: Build dashboard (pull all devices)
        run: |
          RUN_DASH=1 TTN_AFTER_DAYS=7 python scripts/pull_all_devices.py

          # Nach Build: frisch erzeugte Assets loggen
          test -f assets/data.html  && ls -l --time-style=full-iso assets/data.html  || true
          test -f assets/debug.html && ls -l --time-style=full-iso assets/debug.html || true

          # In Pages-Verzeichnis spiegeln
          mkdir -p docs/assets
          cp -r assets/* docs/assets/ || true

      - name: Publish data artifacts to docs/data
        run: |
          mkdir -p docs/data
          cp -a data/*.parquet docs/data/ 2>/dev/null || true
          cp -a data/*.ndjson  docs/data/ 2>/dev/null || true

      - name: Build data index (JSON)
        run: |
          python - << 'PY'
          import json, pathlib
          d = pathlib.Path("docs/data")
          d.mkdir(parents=True, exist_ok=True)
          items = []
          for p in sorted(d.glob("*")):
              if p.suffix.lower() not in (".parquet", ".ndjson"):
                  continue
              st = p.stat()
              items.append({
                  "name": p.name,
                  "size": st.st_size,
                  "mtime": int(st.st_mtime),
                  "type": "Parquet" if p.suffix.lower()==".parquet" else "NDJSON"
              })
          (d / "index.json").write_text(json.dumps(items, ensure_ascii=False), encoding="utf-8")
          PY

      - name: Ensure GitHub Pages flags
        run: |
          mkdir -p docs
          touch docs/.nojekyll

      - name: Sanity check before commit
        run: |
          echo "Listing freshly built assets:"
          ls -l --time-style=full-iso docs/assets/ || true
          echo "Listing data artifacts:"
          ls -l --time-style=full-iso docs/data/ || true

      - name: Commit docs/ and data/ (stash + rebase + push)
        env:
          BRANCH: ${{ github.ref_name }}
        run: |
          set -e
          git config user.name  "ttn-bot"
          git config user.email "ttn-bot@example.com"
          git checkout "$BRANCH"

          git add -A
          git stash push --include-untracked --message "ci-wip" || true

          git pull --rebase origin "$BRANCH" || true

          git stash pop || true

          git add docs/ data/ || true
          git commit -m "update all-devices $(date -u +%FT%TZ)" || echo "no changes"
          git push origin "$BRANCH"

```

**Repo-Einstellungen:**

* Secrets: `TTN_API_KEY`, `TTN_APP_ID`, `TTN_REGION`.
* GitHub Pages so einstellen, dass es `docs/` als Source nimmt.

---

## Troubleshooting

* **HTTP 400 invalid token**
  Neuer Key n√∂tig oder Scopes fehlen.
* **HTTP 400 mit `after`**
  Skript probiert automatisch kleinere `limit`-Werte und ohne `after`.
* **Parquet-Engine fehlt**
  `pyarrow` oder `fastparquet` installieren (Workflow erledigt das).
* **Keine Daten**
  TTN Console pr√ºfen: Storage aktiviert? Device aktiv? Zeitfenster korrekt?
* **429 Rate limit**
  `DELAY_BETWEEN_DEVICES` auf 0.6‚Äì1.0 erh√∂hen.
* **Viele STALE-Ger√§te**
  `STALE_HOURS` anpassen oder per Regex filtern.

---

## Design-Notizen

* Auto-Discovery ‚Üí keine Device-Liste pflegen.
* Pro-Device Parquet ‚Üí inkrementelle Pulls, keine Duplikate.
* Robuste Requests ‚Üí mit Retries/Backoff.
* Health-Report als Text & CSV f√ºr schnellen √úberblick.

üå≤üì° Viel Erfolg beim Monitoring!


---
title: "README dashboard"
subtitle: "version 0.1"
author: "Chris Reudenbach"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true      
    number-depth: 3           

    code-copy: true
    code-link: true
    code-overflow: wrap
    code-fold: true
    highlight-style: github
execute:
  mermaid: true
diagram:
  mermaid:
    engine: kroki
    kroki-url: https://kroki.io
---

# TTN Dashboard – How to Run, Configure, and Deploy

This repo contains a Python script that builds an HTML dashboard from **The Things Network (TTN) Storage**.  
It auto-discovers devices, fetches uplinks, writes per-device Parquet files, and renders interactive plots.

---

## Quick Start (local)

1. (Optional) Create `scripts/.env`:

   ```env
   TTN_APP_ID=gisma-hydro-testbed
   TTN_REGION=eu1
   TTN_API_KEY=NNSXS_...
   RUN_DASH=1
   TTN_AFTER_DAYS=2
   DELAY_BETWEEN_DEVICES=0.3
   # Health report (optional):
   # STALE_HOURS=3
   # DEV_INCLUDE=dds75-lb-.*
   # DEV_EXCLUDE=
````

2. Run:

   ```bash
   python scripts/pull_all_devices.py
   ```

3. Open the dashboard at:

   * `assets/data.html` (main)
   * `assets/debug.html` (raw samples & heads)
   * Health summary: `assets/devices_used.txt` and `assets/devices_used.csv`

---

## Environment Variables

Set these in `.env`, your shell, or GitHub Actions `env:`.
If missing, defaults (in parentheses) are used.

### Required

* `TTN_APP_ID` — your TTN application id (e.g., `gisma-hydro-testbed`)
* `TTN_REGION` — TTN cluster (e.g., `eu1`)
* `TTN_API_KEY` — NNSXS key with scopes:

  * **View end devices** (auto-discovery)
  * **View application packages and associations** (Storage)
  * (helpful) **View application info**, **Read application traffic/data**

### Optional (behavior)

* `RUN_DASH` (`"1"`)
  `1` = build HTML dashboard; `0` = CLI smoke-test mode (see below).
* `TTN_AFTER_DAYS` (`"2"`)
  Sliding storage window: *now − N days*.
  If Parquet exists, the script resumes from the **last saved timestamp**.
* `DELAY_BETWEEN_DEVICES` (`"0.3"`)
  Seconds to sleep between device pulls (avoid rate limits).
* `DEVICES` (unset)
  Whitespace-separated list. If **unset**, the script **auto-discovers** all devices in the app.

### Health Report

* `STALE_HOURS` (`"3"`) — mark as `STALE (xh)` if `last_seen` older than this.
* `DEV_INCLUDE` (`".*"`) — regex include (e.g., `dds75-lb-.*`).
* `DEV_EXCLUDE` (empty) — regex exclude (e.g., `dds75-lb-11`).

---

## Outputs & Layout

* `data/` — per-device Parquet files: `data/<device>.parquet`
* `assets/`

  * `data.html` — interactive dashboard
  * `debug.html` — debug cards with raw NDJSON samples & parquet heads
  * `devices_used.txt` — **human-readable** health summary
  * `devices_used.csv` — **machine-readable** health table

> Note: At start, `devices_used.txt` may temporarily contain only the discovered device list; it’s overwritten at the end with the full health summary.

---

## CLI Smoke-Test

Run an ad-hoc pull for one device without building the full dashboard:

```bash
RUN_DASH=0 python scripts/pull_all_devices.py --device dds75-lb-13 --hours 6 -v
```

* `--hours` overrides `TTN_AFTER_DAYS` **for this run only**.
* Data is merged into `data/<device>.parquet` with de-duplication.

---

## GitHub Actions (Pages or artifact)

Use a workflow like:

```yaml
name: TTN all devices → Pages

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      TTN_API_KEY:  ${{ secrets.TTN_API_KEY }}
      TTN_APP_ID:   ${{ secrets.TTN_APP_ID }}
      TTN_REGION:   ${{ secrets.TTN_REGION }}
      TTN_AFTER_DAYS: "2"
      RUN_DASH: "1"
      DELAY_BETWEEN_DEVICES: "0.4"
      # Leave DEVICES unset for auto-discovery.
      # Optionally add STALE_HOURS / DEV_INCLUDE / DEV_EXCLUDE here.

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pandas plotly pyarrow fastparquet python-dotenv

      - name: Build dashboard
        run: |
          python scripts/pull_all_devices.py
          mkdir -p docs
          cp -r assets/* docs/

      - name: Commit docs/ and data/
        run: |
          git config user.name  "ttn-bot"
          git config user.email "ttn-bot@example.com"
          git add docs/ data/ || true
          git diff --cached --quiet || git commit -m "update all-devices $(date -u +%FT%TZ)"
          git push
```

**Repo settings:**

* Add `TTN_API_KEY` (secret), `TTN_APP_ID`, `TTN_REGION` (secrets or variables).
* Enable **GitHub Pages** to serve the `docs/` folder (or change the workflow to upload a Pages artifact).

---

## Troubleshooting

* **HTTP 400 invalid token**
  Wrong key or missing scopes → create a new API key with the scopes listed above.
* **HTTP 400 with `after`**
  The script automatically retries with smaller `limit` and without `after`.
* **Missing Parquet engine**
  Install `pyarrow` or `fastparquet` (included in the workflow deps).
* **No data**
  Check TTN Console: Storage Integration enabled? Device sent uplinks within window?
* **429 rate limit**
  Increase `DELAY_BETWEEN_DEVICES` to `0.6`–`1.0`.
* **Too many STALE devices**
  Increase `STALE_HOURS` or adjust include/exclude regex.

---

## Design Notes

* Auto-discovery (no device list maintenance).
* Per-device Parquet for incremental pulls & deduplication.
* Robust fetch with retries/backoff and conservative fallbacks.
* Health report written as text & CSV for quick oversight.

